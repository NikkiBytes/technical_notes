{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "# SmartAPI Schema Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema\n",
    "import json\n",
    "from jsonschema import validate\n",
    "import yaml\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from controller.smartapi import SmartAPI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Set Schema \n",
    "SCHEMA: `smartapi_schemav2.json` - this schema file **does not require** a validation on `termsOfService` or `summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file=\"local_schema_folders/smartapi/smartapi_schemav2-path.json\"\n",
    "# Load the schema from a JSON file\n",
    "with open(raw_file, 'r') as schema_file:\n",
    "    schema = json.load(schema_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCHEMA: `smartapi_schemav.json` - this schema file **does require** a validation on `termsOfService` or `summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file=\"smartapi_schema.json\"\n",
    "# Load the schema from a JSON file\n",
    "with open(raw_file, 'r') as schema_file:\n",
    "    schema = json.load(schema_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ct=0\n",
    "for smartapi in SmartAPI.get_all(1000):\n",
    "    doc_ct+=1\n",
    "doc_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_name=\"REPORT_smartapi_schema-FINAL_\"+datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")+\".txt\"\n",
    "\n",
    "# Initialize counters and lists for reporting\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "fail_ids = []\n",
    "fail_details = []\n",
    "error_summary = Counter()\n",
    "missing_properties = Counter()\n",
    "error_categories = Counter()\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary: 243 passed, 0 failed.\n",
      "Skipped Validation IDs: edeb26858bd27d0322af93e7a9e08761, 1138c3297e8e403b6ac10cff5609b319, 1d288b3a3caf75d541ffaae3aab386c8, b772ebfbfa536bba37764d7fddb11d6f, 34bad236d77bea0a0ee6c6cba5be54a6, b99c6dd64abcefe87dcd0a51c249ee6d, f1b8f64c316a01d1722f0fb842499fe5, 02af7d098ab304e80d6f4806c3527027, e481efd21f8e8c1deac05662439c2294, 38e9e5169a72aee3659c9ddba956790d, f339b28426e7bf72028f60feefcd7465, 03283cc2b21c077be6794e1704b1d230, b48c34df08d16311e3bca06b135b828d, cc857d5b7c8b7609b5bbb38ff990bfff, 77ed27f111262d0289ed4f4071faa619, a5b0ec6bfde5008984d4b6cde402d61f, a7f784626a426d054885a5f33f17d3f8, 68f12100e74342ae0dd5013d5f453194, 32f36164fabed5d3abe6c2fd899c9418, 55a223c6c6e0291dbd05f2faf27d16f4, ec6d76016ef40f284359d17fbf78df20, 1f47552dabd67351d4c625adb0a10d00, 5a4c41bf2076b469a0e9cfcf2f2b8f29, e3edd325c76f2992a111b43a907a4870, 316eab811fd9ef1097df98bcaa9f7361, e9eb40ff7ad712e4e6f4f04b964b5966, 00fb85fc776279163199e6c50f6ddfc6, 895ec14a3650ec7ad85959a2d1554e2f\n",
      "Skipped Reasons:\n",
      "ID: edeb26858bd27d0322af93e7a9e08761, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 1138c3297e8e403b6ac10cff5609b319, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 1d288b3a3caf75d541ffaae3aab386c8, Reason: Skipped due to 'responsible developers' error\n",
      "ID: b772ebfbfa536bba37764d7fddb11d6f, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 34bad236d77bea0a0ee6c6cba5be54a6, Reason: Skipped due to 'responsible developers' error\n",
      "ID: b99c6dd64abcefe87dcd0a51c249ee6d, Reason: Skipped due to 'responsible developers' error\n",
      "ID: f1b8f64c316a01d1722f0fb842499fe5, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 02af7d098ab304e80d6f4806c3527027, Reason: Skipped due to 'responsible developers' error\n",
      "ID: e481efd21f8e8c1deac05662439c2294, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 38e9e5169a72aee3659c9ddba956790d, Reason: Skipped due to 'responsible developers' error\n",
      "ID: f339b28426e7bf72028f60feefcd7465, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 03283cc2b21c077be6794e1704b1d230, Reason: Skipped due to 'responsible developers' error\n",
      "ID: b48c34df08d16311e3bca06b135b828d, Reason: Skipped due to 'responsible developers' error\n",
      "ID: cc857d5b7c8b7609b5bbb38ff990bfff, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 77ed27f111262d0289ed4f4071faa619, Reason: Skipped due to 'responsible developers' error\n",
      "ID: a5b0ec6bfde5008984d4b6cde402d61f, Reason: Skipped due to 'responsible developers' error\n",
      "ID: a7f784626a426d054885a5f33f17d3f8, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 68f12100e74342ae0dd5013d5f453194, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 32f36164fabed5d3abe6c2fd899c9418, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 55a223c6c6e0291dbd05f2faf27d16f4, Reason: Skipped due to 'responsible developers' error\n",
      "ID: ec6d76016ef40f284359d17fbf78df20, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 1f47552dabd67351d4c625adb0a10d00, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 5a4c41bf2076b469a0e9cfcf2f2b8f29, Reason: Skipped due to 'responsible developers' error\n",
      "ID: e3edd325c76f2992a111b43a907a4870, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 316eab811fd9ef1097df98bcaa9f7361, Reason: Skipped due to 'responsible developers' error\n",
      "ID: e9eb40ff7ad712e4e6f4f04b964b5966, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 00fb85fc776279163199e6c50f6ddfc6, Reason: Skipped due to 'responsible developers' error\n",
      "ID: 895ec14a3650ec7ad85959a2d1554e2f, Reason: Skipped due to 'responsible developers' error\n"
     ]
    }
   ],
   "source": [
    "with open(report_name, 'w') as report_file:\n",
    "\n",
    "    # Initialize a dictionary to group errors by type\n",
    "    grouped_errors = defaultdict(list)\n",
    "\n",
    "    # Initialize counters and lists for skipped IDs\n",
    "    skip_count = 0\n",
    "    skip_ids = []\n",
    "    skip_reasons = []\n",
    "\n",
    "    # Traverse all SmartAPI entries\n",
    "    for smartapi in SmartAPI.get_all(1000):  # Adjust the argument if needed to control the batch size\n",
    "        try:\n",
    "            # Decode the raw byte data to a string\n",
    "            data_doc = smartapi.raw.decode('utf-8')\n",
    "\n",
    "            # Load the YAML formatted string into a Python dictionary\n",
    "            source_data = yaml.safe_load(data_doc)\n",
    "\n",
    "            # Validate the entry against the schema\n",
    "            validate(instance=source_data, schema=schema)\n",
    "            pass_count += 1  # Increment pass counter\n",
    "\n",
    "        except yaml.YAMLError as ye:\n",
    "            fail_count += 1  # Increment fail counter\n",
    "            fail_ids.append(smartapi._id)  # Append the failed entry's ID\n",
    "            error_message = f\"YAML Error: {ye}\"\n",
    "            grouped_errors[error_message].append(smartapi._id)\n",
    "            \n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            # Ignore errors related to \"responsible developers\"\n",
    "            if 'responsible developers' in str(ve):\n",
    "                skip_count += 1  # Increment skip counter\n",
    "                skip_ids.append(smartapi._id)  # Append the skipped entry's ID\n",
    "                skip_reasons.append(\"Skipped due to 'responsible developers' error\")\n",
    "                continue\n",
    "            fail_count += 1  # Increment fail counter\n",
    "            fail_ids.append(smartapi._id)  # Append the failed entry's ID\n",
    "            error_message = f\"Schema Validation Error: {ve}\"\n",
    "            grouped_errors[error_message].append(smartapi._id)\n",
    "\n",
    "            # Additional processing for error categories\n",
    "            if 'is a required property' in str(ve):\n",
    "                missing_prop = str(ve).split(\"'\")[1]  # Extract the missing property name\n",
    "                missing_properties[missing_prop] += 1\n",
    "            if 'enum' in str(ve):\n",
    "                error_categories['Enum Constraint Violations'] += 1\n",
    "            elif 'additionalProperties' in str(ve):\n",
    "                error_categories['Unexpected Properties'] += 1\n",
    "            else:\n",
    "                error_categories['Other Errors'] += 1\n",
    "\n",
    "    total_entries = pass_count + fail_count\n",
    "    percent_passed = (pass_count / total_entries * 100) if total_entries else 0\n",
    "    percent_failed = (fail_count / total_entries * 100) if total_entries else 0\n",
    "    unique_error_ids = len(set(fail_ids))\n",
    "\n",
    "    # Write the top summary statistics\n",
    "    report_file.write(f\"Validation Report Generated on {datetime.datetime.now()}\\n\")\n",
    "    report_file.write(\"-------------------------------------------------\\n\")\n",
    "    report_file.write(f\"Total Entries Processed: {total_entries}\\n\")\n",
    "    report_file.write(f\"Total Passed: {pass_count} ({percent_passed:.2f}%)\\n\")\n",
    "    report_file.write(f\"Total Failed: {fail_count} ({percent_failed:.2f}%)\\n\")\n",
    "    report_file.write(f\"Total Skipped: {skip_count}\\n\\n\")\n",
    "\n",
    "    # Error Type Summary\n",
    "    if error_summary:\n",
    "        report_file.write(\"Error Type Summary:\\n\")\n",
    "        for error_type, count in error_summary.items():\n",
    "            report_file.write(f\"{error_type}: {count}\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Validation Error Categories\n",
    "    if error_categories:\n",
    "        report_file.write(\"Validation Error Categories Summary:\\n\")\n",
    "        for category, count in error_categories.items():\n",
    "            report_file.write(f\"{category}: {count} times\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Missing Required Properties\n",
    "    if missing_properties:\n",
    "        report_file.write(\"Missing Required Property Summary:\\n\")\n",
    "        for prop, count in missing_properties.items():\n",
    "            report_file.write(f\"Missing '{prop}': {count} times\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Most Common Errors\n",
    "    if error_categories:\n",
    "        most_common_error = max(error_categories, key=error_categories.get)\n",
    "        report_file.write(f\"Most Common Error Type: {most_common_error} ({error_categories[most_common_error]} occurrences)\\n\\n\")\n",
    "\n",
    "    # Summary of Most Common Missing Properties\n",
    "    if missing_properties:\n",
    "        most_common_missing_prop = max(missing_properties, key=missing_properties.get)\n",
    "        report_file.write(f\"Most Common Missing Property: '{most_common_missing_prop}' ({missing_properties[most_common_missing_prop]} times)\\n\\n\")\n",
    "\n",
    "    # Grouped Error Details\n",
    "    if grouped_errors:\n",
    "        report_file.write(\"Grouped Error Details:\\n\")\n",
    "        report_file.write(\"-------------------------------------------------\\n\")\n",
    "        for error, ids in grouped_errors.items():\n",
    "            report_file.write(f\"{error} occurred for the following IDs:\\n\")\n",
    "            report_file.write(\", \".join(ids) + \"\\n\")\n",
    "            report_file.write(\"-------------------------------------------------\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "    # Skipped IDs and Reasons\n",
    "    if skip_count > 0:\n",
    "        report_file.write(\"Skipped IDs and Reasons:\\n\")\n",
    "        report_file.write(\"-------------------------------------------------\\n\")\n",
    "        for i in range(len(skip_ids)):\n",
    "            report_file.write(f\"ID: {skip_ids[i]}, Reason: {skip_reasons[i]}\\n\")\n",
    "            report_file.write(\"-------------------------------------------------\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "    # Optionally, you can also print the summary to the console\n",
    "    print(f\"Validation Summary: {pass_count} passed, {fail_count} failed.\")\n",
    "    if unique_error_ids > 0:\n",
    "        print(f\"Summary Count of Unique Error IDs: {unique_error_ids}\")\n",
    "    if fail_ids:\n",
    "        print(f\"Failed Validation IDs: {', '.join(fail_ids)}\")\n",
    "    if skip_count > 0:\n",
    "        print(f\"Skipped Validation IDs: {', '.join(skip_ids)}\")\n",
    "        print(\"Skipped Reasons:\")\n",
    "        for i in range(len(skip_ids)):\n",
    "            print(f\"ID: {skip_ids[i]}, Reason: {skip_reasons[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file=\"local_schema_folders/smartapi/smartapi_schemav2-path.json\"\n",
    "# Load the schema from a JSON file\n",
    "with open(raw_file, 'r') as schema_file:\n",
    "    schema = json.load(schema_file)\n",
    "    \n",
    "report_name=\"REPORT_SUMMARY_smartapi_schema-xpath_\"+datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")+\".txt\"\n",
    "\n",
    "# Initialize counters and lists for reporting\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "fail_ids = []\n",
    "fail_details = []\n",
    "error_summary = Counter()\n",
    "missing_properties = Counter()\n",
    "error_categories = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report and ignore `responsible developers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary: 243 passed, 0 failed.\n"
     ]
    }
   ],
   "source": [
    "with open(report_name, 'w') as report_file:\n",
    "    # Traverse all SmartAPI entries\n",
    "    for smartapi in SmartAPI.get_all(1000):  # Adjust the argument if needed to control the batch size\n",
    "        try:\n",
    "            # Decode the raw byte data to a string\n",
    "            data_doc = smartapi.raw.decode('utf-8')\n",
    "\n",
    "            # Load the YAML formatted string into a Python dictionary\n",
    "            source_data = yaml.safe_load(data_doc)\n",
    "\n",
    "            # Validate the entry against the schema\n",
    "            validate(instance=source_data, schema=schema)\n",
    "            pass_count += 1  # Increment pass counter\n",
    "\n",
    "        except yaml.YAMLError as ye:\n",
    "            fail_count += 1  # Increment fail counter\n",
    "            fail_ids.append(smartapi._id)  # Append the failed entry's ID\n",
    "            fail_details.append(f\"YAML Error for ID {smartapi._id}: {ye}\")\n",
    "        except jsonschema.exceptions.ValidationError as ve:\n",
    "            # Ignore errors related to \"responsible developers\"\n",
    "            if 'responsible developers' in str(ve):\n",
    "                continue\n",
    "            fail_count += 1  # Increment fail counter\n",
    "            fail_ids.append(smartapi._id)  # Append the failed entry's ID\n",
    "            error_message = f\"Schema Validation Error for ID {smartapi._id}: {ve}\"\n",
    "            fail_details.append(error_message)\n",
    "            # Check if error is about a missing required property\n",
    "            if 'is a required property' in str(ve):\n",
    "                missing_prop = str(ve).split(\"'\")[1]  # Extract the missing property name\n",
    "                missing_properties[missing_prop] += 1\n",
    "            # Categorize and count other types of validation errors\n",
    "            if 'enum' in str(ve):\n",
    "                error_categories['Enum Constraint Violations'] += 1\n",
    "            elif 'additionalProperties' in str(ve):\n",
    "                error_categories['Unexpected Properties'] += 1\n",
    "            else:\n",
    "                error_categories['Other Errors'] += 1\n",
    "\n",
    "    total_entries = pass_count + fail_count\n",
    "    percent_passed = (pass_count / total_entries * 100) if total_entries else 0\n",
    "    percent_failed = (fail_count / total_entries * 100) if total_entries else 0\n",
    "    unique_error_ids = len(set(fail_ids))\n",
    "\n",
    "    # Write the top summary statistics\n",
    "    report_file.write(f\"Validation Report Generated on {datetime.datetime.now()}\\n\")\n",
    "    report_file.write(\"-------------------------------------------------\\n\")\n",
    "    report_file.write(f\"Total Entries Processed: {total_entries}\\n\")\n",
    "    report_file.write(f\"Total Passed: {pass_count} ({percent_passed:.2f}%)\\n\")\n",
    "    report_file.write(f\"Total Failed: {fail_count} ({percent_failed:.2f}%)\\n\\n\")\n",
    "\n",
    "    # Error Type Summary\n",
    "    if error_summary:\n",
    "        report_file.write(\"Error Type Summary:\\n\")\n",
    "        for error_type, count in error_summary.items():\n",
    "            report_file.write(f\"{error_type}: {count}\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Validation Error Categories\n",
    "    if error_categories:\n",
    "        report_file.write(\"Validation Error Categories Summary:\\n\")\n",
    "        for category, count in error_categories.items():\n",
    "            report_file.write(f\"{category}: {count} times\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Missing Required Properties\n",
    "    if missing_properties:\n",
    "        report_file.write(\"Missing Required Property Summary:\\n\")\n",
    "        for prop, count in missing_properties.items():\n",
    "            report_file.write(f\"Missing '{prop}': {count} times\\n\")\n",
    "\n",
    "    report_file.write(\"\\n\")\n",
    "\n",
    "    # Summary of Most Common Errors\n",
    "    if error_categories:\n",
    "        most_common_error = max(error_categories, key=error_categories.get)\n",
    "        report_file.write(f\"Most Common Error Type: {most_common_error} ({error_categories[most_common_error]} occurrences)\\n\\n\")\n",
    "\n",
    "    # Summary of Most Common Missing Properties\n",
    "    if missing_properties:\n",
    "        most_common_missing_prop = max(missing_properties, key=missing_properties.get)\n",
    "        report_file.write(f\"Most Common Missing Property: '{most_common_missing_prop}' ({missing_properties[most_common_missing_prop]} times)\\n\\n\")\n",
    "\n",
    "    # Summary List of Error IDs\n",
    "    if fail_ids:\n",
    "        report_file.write(\"Summary List of Error IDs:\\n\")\n",
    "        report_file.write(\", \".join(fail_ids) + \"\\n\\n\")\n",
    "\n",
    "    # Summary Count of Unique Error IDs\n",
    "    if unique_error_ids > 0:\n",
    "        report_file.write(f\"Summary Count of Unique Error IDs: {unique_error_ids}\\n\\n\")\n",
    "\n",
    "    # # Detailed Error Reports\n",
    "    # if fail_details:\n",
    "    #     report_file.write(\"Detailed Error Reports:\\n\")\n",
    "    #     report_file.write(\"-------------------------------------------------\\n\")\n",
    "    #     for detail in fail_details:\n",
    "    #         report_file.write(detail + \"\\n\")\n",
    "    #         report_file.write(\"-------------------------------------------------\\n\")\n",
    "    #     report_file.write(\"\\n\")\n",
    "\n",
    "# Optionally, you can also print the summary to the console\n",
    "print(f\"Validation Summary: {pass_count} passed, {fail_count} failed.\")\n",
    "if unique_error_ids > 0:\n",
    "    print(f\"Summary Count of Unique Error IDs: {unique_error_ids}\")\n",
    "if fail_ids:\n",
    "    print(f\"Failed Validation IDs: {', '.join(fail_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summary Schema Comparison report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize counters and lists for reporting\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "fail_ids = []\n",
    "fail_details = []\n",
    "error_summary = Counter()\n",
    "missing_properties = Counter()\n",
    "error_categories = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of schema files\n",
    "schema_files = [\"smartapi_schemav1.json\", \"smartapi_schemav2-path.json\", \"smartapi_schemav2-xpath.json\"]\n",
    "\n",
    "# Create a report file\n",
    "report_name = \"report_smartapi_summary_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".txt\"\n",
    "with open(report_name, 'w') as report_file:\n",
    "\n",
    "    # Initialize overall counters for the summary statistics\n",
    "    overall_pass_count = 0\n",
    "    overall_fail_count = 0\n",
    "    overall_error_categories = {}\n",
    "    overall_missing_properties = {}\n",
    "\n",
    "    # Loop through each schema file\n",
    "    for raw_file in schema_files:\n",
    "        # Initialize counters for the summary statistics per schema\n",
    "        schema_pass_count = 0\n",
    "        schema_fail_count = 0\n",
    "        schema_error_categories = {}\n",
    "        schema_missing_properties = {}\n",
    "\n",
    "        # Load the schema from a JSON file\n",
    "        with open(raw_file, 'r') as schema_file:\n",
    "            schema = json.load(schema_file)\n",
    "\n",
    "        # Run validation twice, once with \"responsible developers\" error and once ignoring it\n",
    "        for ignore_dev_errors in [False, True]:\n",
    "            # Initialize counters for reporting\n",
    "            pass_count = 0\n",
    "            fail_count = 0\n",
    "\n",
    "            # Traverse all SmartAPI entries\n",
    "            for smartapi in SmartAPI.get_all(1000):  # Adjust the argument if needed to control the batch size\n",
    "                try:\n",
    "                    # Decode the raw byte data to a string\n",
    "                    data_doc = smartapi.raw.decode('utf-8')\n",
    "\n",
    "                    # Load the YAML formatted string into a Python dictionary\n",
    "                    source_data = yaml.safe_load(data_doc)\n",
    "\n",
    "                    # Validate the entry against the schema\n",
    "                    validate(instance=source_data, schema=schema)\n",
    "                    pass_count += 1  # Increment pass counter\n",
    "\n",
    "                except yaml.YAMLError as ye:\n",
    "                    fail_count += 1  # Increment fail counter\n",
    "                except jsonschema.exceptions.ValidationError as ve:\n",
    "                    # Ignore errors related to \"responsible developers\" if ignore_dev_errors is True\n",
    "                    if ignore_dev_errors and 'responsible developers' in str(ve):\n",
    "                        continue\n",
    "\n",
    "                    # Update error categories and missing properties\n",
    "                    error_msg = str(ve)\n",
    "                    if 'enum' in error_msg:\n",
    "                        category = \"Enum Constraint Violations\"\n",
    "                    else:\n",
    "                        category = \"Other Errors\"\n",
    "\n",
    "                    if category not in schema_error_categories:\n",
    "                        schema_error_categories[category] = 0\n",
    "                    schema_error_categories[category] += 1\n",
    "\n",
    "                    if 'is a required property' in error_msg:\n",
    "                        missing_property = error_msg.split(\"'\")[1]\n",
    "                        if missing_property not in schema_missing_properties:\n",
    "                            schema_missing_properties[missing_property] = 0\n",
    "                        schema_missing_properties[missing_property] += 1\n",
    "\n",
    "                    fail_count += 1  # Increment fail counter\n",
    "\n",
    "            total_entries = pass_count + fail_count\n",
    "            percent_passed = (pass_count / total_entries * 100) if total_entries else 0\n",
    "            percent_failed = (fail_count / total_entries * 100) if total_entries else 0\n",
    "\n",
    "            # Update the summary statistics for the schema\n",
    "            schema_pass_count += pass_count\n",
    "            schema_fail_count += fail_count\n",
    "\n",
    "            # Write the summary statistics for the current validation run to the report file\n",
    "            report_file.write(f\"Validation Report for {raw_file} (Ignoring 'responsible developers' errors: {ignore_dev_errors}) Generated on {datetime.datetime.now()}\\n\")\n",
    "            report_file.write(\"-------------------------------------------------\\n\")\n",
    "            report_file.write(f\"Total Entries Processed: {total_entries}\\n\")\n",
    "            report_file.write(f\"Total Passed: {pass_count} ({percent_passed:.2f}%)\\n\")\n",
    "            report_file.write(f\"Total Failed: {fail_count} ({percent_failed:.2f}%)\\n\\n\")\n",
    "\n",
    "        # Write the schema-level summary to the report file\n",
    "        report_file.write(f\"Summary for {raw_file}:\\n\")\n",
    "        report_file.write(\"-------------------------------------------------\\n\")\n",
    "\n",
    "        # Summary of Validation Error Categories\n",
    "        if schema_error_categories:\n",
    "            report_file.write(\"Validation Error Categories Summary:\\n\")\n",
    "            for category, count in schema_error_categories.items():\n",
    "                report_file.write(f\"{category}: {count} times\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "        # Summary of Missing Required Properties\n",
    "        if schema_missing_properties:\n",
    "            report_file.write(\"Missing Required Property Summary:\\n\")\n",
    "            for prop, count in schema_missing_properties.items():\n",
    "                report_file.write(f\"Missing '{prop}': {count} times\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "        # Summary of Most Common Errors\n",
    "        if schema_error_categories:\n",
    "            most_common_error = max(schema_error_categories, key=schema_error_categories.get)\n",
    "            report_file.write(f\"Most Common Error Type: {most_common_error} ({schema_error_categories[most_common_error]} occurrences)\\n\\n\")\n",
    "\n",
    "        # Summary of Most Common Missing Properties\n",
    "        if schema_missing_properties:\n",
    "            most_common_missing_prop = max(schema_missing_properties, key=schema_missing_properties.get)\n",
    "            report_file.write(f\"Most Common Missing Property: '{most_common_missing_prop}' ({schema_missing_properties[most_common_missing_prop]} times)\\n\\n\")\n",
    "\n",
    "        # Update overall summary statistics\n",
    "        overall_pass_count += schema_pass_count\n",
    "        overall_fail_count += schema_fail_count\n",
    "        for category, count in schema_error_categories.items():\n",
    "            if category not in overall_error_categories:\n",
    "                overall_error_categories[category] = 0\n",
    "            overall_error_categories[category] += count\n",
    "        for prop, count in schema_missing_properties.items():\n",
    "            if prop not in overall_missing_properties:\n",
    "                overall_missing_properties[prop] = 0\n",
    "            overall_missing_properties[prop] += count\n",
    "\n",
    "        # Write the overall summary statistics to the report file\n",
    "        report_file.write(\"Overall Summary:\\n\")\n",
    "        report_file.write(\"-------------------------------------------------\\n\")\n",
    "        report_file.write(f\"Total Entries Processed: {overall_pass_count + overall_fail_count}\\n\")\n",
    "        report_file.write(f\"Total Passed: {overall_pass_count}\\n\")\n",
    "        report_file.write(f\"Total Failed: {overall_fail_count}\\n\\n\")\n",
    "\n",
    "            # Summary of Validation Error Categories\n",
    "        if overall_error_categories:\n",
    "            report_file.write(\"Overall Validation Error Categories Summary:\\n\")\n",
    "            for category, count in overall_error_categories.items():\n",
    "                report_file.write(f\"{category}: {count} times\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "        # Summary of Missing Required Properties\n",
    "        if overall_missing_properties:\n",
    "            report_file.write(\"Overall Missing Required Property Summary:\\n\")\n",
    "            for prop, count in overall_missing_properties.items():\n",
    "                report_file.write(f\"Missing '{prop}': {count} times\\n\")\n",
    "        report_file.write(\"\\n\")\n",
    "\n",
    "        # Summary of Most Common Errors\n",
    "        if overall_error_categories:\n",
    "            most_common_error = max(overall_error_categories, key=overall_error_categories.get)\n",
    "            report_file.write(f\"Most Common Error Type: {most_common_error} ({overall_error_categories[most_common_error]} occurrences)\\n\\n\")\n",
    "\n",
    "        # Summary of Most Common Missing Properties\n",
    "        if overall_missing_properties:\n",
    "            most_common_missing_prop = max(overall_missing_properties, key=overall_missing_properties.get)\n",
    "            report_file.write(f\"Most Common Missing Property: '{most_common_missing_prop}' ({overall_missing_properties[most_common_missing_prop]} times)\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_files = [\"smartapi_schemav1.json\",\"smartapi_schemav2-path.json\", \"smartapi_schemav2-xpath.json\"]\n",
    "\n",
    "# Create a report file\n",
    "report_name = \"report_smartapi_summary_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".txt\"\n",
    "error_file_name = \"error_smartapi_summary_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".txt\"\n",
    "\n",
    "with open(report_name, 'w') as report_file, open(error_file_name, 'w') as error_file:\n",
    "\n",
    "    # Write the title for the report\n",
    "    report_file.write(\"SmartAPI Schema Validation Report\\n\")\n",
    "    report_file.write(\"==================================\\n\\n\")\n",
    "\n",
    "    # Loop through each schema file\n",
    "    for raw_file in schema_files:\n",
    "\n",
    "        # Load the schema from a JSON file\n",
    "        with open(raw_file, 'r') as schema_file:\n",
    "            schema = json.load(schema_file)\n",
    "\n",
    "        # Run validation twice, once with \"responsible developers\" error and once ignoring it\n",
    "        for ignore_dev_errors in [False, True]:\n",
    "            # Initialize counters for reporting\n",
    "            pass_count = 0\n",
    "            fail_count = 0\n",
    "            # Initialize counters for the summary statistics per schema\n",
    "            schema_pass_count = 0\n",
    "            schema_fail_count = 0\n",
    "            schema_error_categories = {}\n",
    "            schema_missing_properties = {}\n",
    "\n",
    "            try:    \n",
    "                # Traverse all SmartAPI entries\n",
    "                for smartapi in SmartAPI.get_all(1000):  # Adjust the argument if needed to control the batch size\n",
    "                    try:\n",
    "                        # Decode the raw byte data to a string\n",
    "                        data_doc = smartapi.raw.decode('utf-8')\n",
    "\n",
    "                        # Load the YAML formatted string into a Python dictionary\n",
    "                        source_data = yaml.safe_load(data_doc)\n",
    "\n",
    "                        # Validate the entry against the schema\n",
    "                        validate(instance=source_data, schema=schema)\n",
    "                        pass_count += 1  # Increment pass counter\n",
    "\n",
    "                    except yaml.YAMLError as ye:\n",
    "                        fail_count += 1  # Increment fail counter\n",
    "                    except jsonschema.exceptions.ValidationError as ve:\n",
    "                        # Ignore errors related to \"responsible developers\" if ignore_dev_errors is True\n",
    "                        if ignore_dev_errors and 'responsible developers' in str(ve):\n",
    "                            continue\n",
    "\n",
    "                        # Update error categories and missing properties\n",
    "                        error_msg = str(ve)\n",
    "                        if 'enum' in error_msg:\n",
    "                            category = \"Enum Constraint Violations\"\n",
    "                        else:\n",
    "                            category = \"Other Errors\"\n",
    "\n",
    "                        if category not in schema_error_categories:\n",
    "                            schema_error_categories[category] = 0\n",
    "                        schema_error_categories[category] += 1\n",
    "\n",
    "                        if 'is a required property' in error_msg:\n",
    "                            missing_property = error_msg.split(\"'\")[1]\n",
    "                            if missing_property not in schema_missing_properties:\n",
    "                                schema_missing_properties[missing_property] = 0\n",
    "                            schema_missing_properties[missing_property] += 1\n",
    "\n",
    "                        fail_count += 1  # Increment fail counter\n",
    "            except Exception as e:  # Catch all exceptions\n",
    "                error_file.write(f\"Skipped entry ID: {smartapi.id}, Error: {str(e)}\\n\")\n",
    "                fail_count += 1  # Increment fail counter\n",
    "\n",
    "            total_entries = pass_count + fail_count\n",
    "            percent_passed = (pass_count / total_entries * 100) if total_entries else 0\n",
    "            percent_failed = (fail_count / total_entries * 100) if total_entries else 0\n",
    "\n",
    "            # Update the summary statistics for the schema\n",
    "            schema_pass_count += pass_count\n",
    "            schema_fail_count += fail_count\n",
    "\n",
    "            # Write the summary statistics for the current validation run to the report file\n",
    "            report_file.write(f\"Validation Report for {raw_file} (Ignoring 'responsible developers' errors: {ignore_dev_errors}) Generated on {datetime.datetime.now()}\\n\")\n",
    "            report_file.write(\"-------------------------------------------------\\n\")\n",
    "            report_file.write(f\"Total Entries Processed: {total_entries}\\n\")\n",
    "            report_file.write(f\"Total Passed: {pass_count} ({percent_passed:.2f}%)\\n\")\n",
    "            report_file.write(f\"Total Failed: {fail_count} ({percent_failed:.2f}%)\\n\\n\")\n",
    "\n",
    "            # Write the overall summary statistics to the report file for the current schema\n",
    "            report_file.write(f\"Overall Summary for {raw_file}:\\n\")\n",
    "            report_file.write(f\"Total Entries Processed: {schema_pass_count + schema_fail_count}\\n\")\n",
    "            report_file.write(f\"Total Passed: {schema_pass_count}\\n\")\n",
    "            report_file.write(f\"Total Failed: {schema_fail_count}\\n\\n\")\n",
    "\n",
    "            # Summary of Missing Required Properties for the current schema\n",
    "            if schema_missing_properties:\n",
    "                report_file.write(f\"Overall Missing Required Property Summary for {raw_file}:\\n\")\n",
    "                for prop, count in schema_missing_properties.items():\n",
    "                    report_file.write(f\"Missing '{prop}': {count} times\\n\")\n",
    "            report_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controller.smartapi import SmartAPI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Properties \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path**  \n",
    " e712b9eb07e637a00ae468f757ce2a1f,342e4cec92030d74efd84b61650fb0ea, 67cc0e21b6238472f6f1f00e6b7c32aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = ['e712b9eb07e637a00ae468f757ce2a1f', '342e4cec92030d74efd84b61650fb0ea', '67cc0e21b6238472f6f1f00e6b7c32aa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openapi: 3.0.0\n",
      "info:\n",
      "  title: REST API for Gene ID Conversion\n",
      "  version: \"1.0.0\"\n",
      "  description: |\n",
      "    Genomic and gene expression data is integral to biomolecular data analysis. The types of identifiers used for genes differ across different resources providing such data sets. The ability to use a single type of gene identifier is imperative for integrating data from two or more resources. This gene ID conversion tool facilitates the use of a common gene identifier. Gene SYMBOL is likely the most common gene ID type a user will search for. A general user does not know in advance whether a gene symbol is indeed a gene SYMBOL or ALIAS. This is often seen for a small percentage of genes with change in the genome/transcriptome version. This tool generates various types of gene IDs (Entrez gene ID, symbol, gene name, Ensembl ID, Uniprot ID, REFSEQ ID, etc.) for a given gene ID type (e.g., symbol or alias). This tool also generate URLs to various commonly used data resources (NCBI Entrez, Ensembl, KEGG, Genecards, etc.). The REST API provides HTTPS-based access to this tool via a web-browser or scripts in several programming languages such as PHP, R, Python, that can handle HTTPS requests.\n",
      "    A full-UI non-API version is available at https://bdcw.org/geneid/geneidconv.php. This tool is based on R Bioconductor package org.Xy.eg.db and NCBI Entrez gene_info. It performs seamless searching in both SYMBOL (first) and ALIAS (if not found in SYMBOL). In the non-API version, when multiple references satisfy a given ID, the user is given an option to choose the specific gene one for which one wants to get further information. \n",
      "  license:\n",
      "    name: Gene ID Conversion Terms of Use\n",
      "    url: https://bdcw.org/geneid/termsofuse.php\n",
      "  contact:\n",
      "    url: https://bdcw.org/geneid/contact.php\n",
      "servers:\n",
      "  - description: Gene ID Conversion\n",
      "    url: https://bdcw.org/geneid/rest\n",
      "paths:\n",
      "  #/species/hsa/GeneIDType/SYMBOL_OR_ALIAS/GeneListStr/PNPLA3/View/json\n",
      "  /species/{species_id}/GeneIDType/{geneid_type}/GeneListStr/{gene_id}/View/{json_or_txt}:\n",
      "    get:\n",
      "      description: Fetch all the different ID types for a gene or a set of genes specified as one gene ID type. The format for the list of genes is GENE1__GENE2 (use comma (,) or __ as separator).\n",
      "      parameters:\n",
      "      #Types of parameters: https://swagger.io/docs/specification/describing-parameters\n",
      "      - in: path\n",
      "        name: species_id\n",
      "        description: The unique species name or identifier \n",
      "        schema:\n",
      "          type: string\n",
      "        example: hsa, human, mouse, mmu, rno, rat\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: geneid_type\n",
      "        description: The unique Gene ID type such as ENTREZID, SYMBOL, SYMBOL_OR_ALIAS, UNIPROT, ENSEMBL or REFSEQ [and HGNC for hsa]\n",
      "        schema:\n",
      "          type: string\n",
      "        example: SYMBOL\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: gene_id\n",
      "        description: The unigue gene identifier in any one of the known formats or a comma (or double underscore __) separated list of identifiers corresponding to geneid_type\n",
      "        schema:\n",
      "          type: string\n",
      "          example: HK1, 3098, HK1,RPE, HK1__RPE, 3098__6120, ENSG00000100344, NM_025225, Q9NST1\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: json_or_txt\n",
      "        description: The output (View) format, json or txt\n",
      "        schema:\n",
      "          type: string\n",
      "          example: json, txt\n",
      "        required: true\n",
      "      responses:\n",
      "        #https://swagger.io/docs/specification/describing-responses/\n",
      "        '200':\n",
      "          description: Result of gene ID conversion as a json object\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                type: object\n",
      "                properties:\n",
      "                  SYMBOL:\n",
      "                    type: string\n",
      "                    description: Gene Symbol\n",
      "                  ENTREZID:\n",
      "                    type: string\n",
      "                    description: Entrez Gene ID\n",
      "                  ALIAS:\n",
      "                    type: string\n",
      "                    description: Alias for the Gene Symbol\n",
      "                  GENENAME:\n",
      "                    type: string\n",
      "                    description: Full gene name\n",
      "                  ENSEMBL:\n",
      "                    type: string\n",
      "                    description: Ensembl ID for the Gene\n",
      "                  REFSEQ:\n",
      "                    type: string\n",
      "                    description: RefSeq ID for the Gene\n",
      "                  UNIPROT:\n",
      "                    type: string\n",
      "                    description: UniProt ID for the Gene Symbol\n",
      "                  KEGG:\n",
      "                    type: string\n",
      "                    description: ID for the gene in KEGG DB, general same as ENTREZID\n",
      "          x-responseValueType:\n",
      "          - x-path: SYMBOL\n",
      "            x-valueType: https://identifiers.org/ncbigene \n",
      "          - x-path: ENTREZID\n",
      "            x-valueType: https://identifiers.org/ncbigene \n",
      "          - x-path: ALIAS\n",
      "            x-valueType: https://identifiers.org/ncbigene \n",
      "          - x-path: GENENAME\n",
      "            x-valueType: https://identifiers.org/ncbigene \n",
      "          - x-path: ENSEMBL\n",
      "            x-valueType: https://identifiers.org/ensembl \n",
      "          - x-path: REFSEQ\n",
      "            x-valueType: https://identifiers.org/refseq \n",
      "          - x-path: UNIPROT\n",
      "            x-valueType: https://identifiers.org/uniprot\n",
      "          - x-path: KEGG\n",
      "            x-valueType: https://identifiers.org/kegg.genes\n",
      "        '406':\n",
      "          description: URL/path format not acceptable\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                $ref: '#/components/schemas/Error'\n",
      "components:\n",
      "  responses:\n",
      "    NotFound:\n",
      "      description: The specified resource was not found\n",
      "      content:\n",
      "        application/json:\n",
      "          schema:\n",
      "            $ref: '#/components/schemas/Error'\n",
      "    Unauthorized:\n",
      "      description: Unauthorized\n",
      "      content:\n",
      "        application/json:\n",
      "          schema:\n",
      "            $ref: '#/components/schemas/Error'\n",
      "  schemas:\n",
      "    # Schema for error response body\n",
      "    Error:\n",
      "      type: object\n",
      "      properties:\n",
      "        code:\n",
      "          type: string\n",
      "        message:\n",
      "          type: string\n",
      "      required:\n",
      "        - code\n",
      "        - message\n",
      "        \n",
      "\n",
      "openapi: 3.0.0\n",
      "info:\n",
      "  title: MetGENE REST API\n",
      "  version: \"1.0.0\"\n",
      "  description: |\n",
      "    The MetGENE REST service enables access to a variety of data (including reactions, metabolites and studies for a certain gene or list of genes) using HTTP requests. These requests may be carried out using a web browser or may be embedded in 3rd party applications or scripts to enable programmatic access. Most modern programming languages including PHP, Perl, Python, Java and Javascript have the capability to create HTTP request and interact with datasets such as this REST service.\n",
      "  license:\n",
      "    name: Terms of Use\n",
      "    url: https://bdcw.org/MetGENE/termsofuse.php\n",
      "  contact:\n",
      "    name: Contact\n",
      "    url: https://bdcw.org/MetGENE/contact.php\n",
      "servers:\n",
      "  - description: MetGENE\n",
      "    url: https://bdcw.org/MetGENE/rest\n",
      "paths:\n",
      "  /reactions/species/{species_id}/GeneIDType/{geneID_type}/GeneInfoStr/{gene_ID}/anatomy/NA/disease/NA/phenotype/NA/viewType/{vtf}:\n",
      "    get:\n",
      "      description: Fetch all the reactions for a given species, gene or list of genes. Anatomy, disease and phenotype inputs are not needed as reactions are not specific for these.\n",
      "      parameters:\n",
      "      - in: path\n",
      "        name: species_id\n",
      "        description: The unique species name or identifier \n",
      "        schema:\n",
      "          type: string\n",
      "        example: hsa\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: geneID_type\n",
      "        description: The unique Gene ID type like ENTREZID, SYMBOL, SYMBOL_OR_ALIAS, UNIPROT, ENSEMBL or REFSEQ\n",
      "        schema:\n",
      "          type: string\n",
      "        example: SYMBOL\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: gene_ID\n",
      "        description: The unigue gene identifier in any one of the known formats or double tab separated list of identifiers\n",
      "        schema:\n",
      "          type: string\n",
      "          example: HK1\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: vtf\n",
      "        description: Media type e.g. json or txt\n",
      "        schema:\n",
      "          type: string\n",
      "          example: json or txt \n",
      "        required: true\n",
      "      responses:\n",
      "        '200':\n",
      "          description: Success\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                type: object\n",
      "                properties:\n",
      "                  Gene:\n",
      "                    type: string\n",
      "                    description: Entrez Gene ID\n",
      "                  KEGG_REACTION_ID:\n",
      "                    type: string\n",
      "                    description: KEGG Reaction IDs\n",
      "                  KEGG_REACTION_NAME:\n",
      "                    type: string\n",
      "                    description: Verbose KEGG reaction name\n",
      "                  KEGG_REACTION_EQN:\n",
      "                    type: string\n",
      "                    description: KEGG Reaction Equation\n",
      "            text/plain:\n",
      "              schema:\n",
      "                type: string\n",
      "                example: pong\n",
      "          x-responseValueType:\n",
      "          - x-path: gene_id\n",
      "            x-valueType: https://identifiers.org/ncbigene\n",
      "          - x-path: KEGG_REACTION_ID\n",
      "            x-valueType: https://www.genome.jp/kegg/reaction/\n",
      "          - x-path: KEGG_REACTION_NAME\n",
      "            x-valueType: https://www.genome.jp/kegg/reaction/\n",
      "  /metabolites/species/{species_id}/GeneIDType/{geneID_type}/GeneInfoStr/{gene_ID}/anatomy/{anatomy_name}/disease/{disease_name}/phenotype/{phenotype_name}/viewType/{vtf}:\n",
      "    get:\n",
      "      description: Fetch all the metabolites for a given species, gene or list of genes, anatomy or tissue type, disease and phenotype.\n",
      "      parameters:\n",
      "      - in: path\n",
      "        name: species_id\n",
      "        description: The unique species name or identifier  like hsa, Human, mmu, Mouse.\n",
      "        schema:\n",
      "          type: string\n",
      "        example: hsa\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: geneID_type\n",
      "        description: The unique Gene ID type like ENTREZID, SYMBOL, SYMBOL_OR_ALIAS, UNIPROT, ENSEMBL or REFSEQ\n",
      "        schema:\n",
      "          type: string\n",
      "        example: SYMBOL\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: gene_ID\n",
      "        description: The unigue gene identifier (e.g. 3098) in any one of the known formats (e.g. ENTREZID ) or double underscore separated list of identifiers (3098__6120)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: HK1\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: anatomy_name\n",
      "        description: The anatomy or tissue name (e.g. Blood, Lung, Liver)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: Blood or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: disease_name\n",
      "        description: The disease name (e.g. Diabetes, Fatty liver disease)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: Diabetes or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: phenotype_name\n",
      "        description: The phenotype name (e.g. BMI)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: BMI or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: vtf\n",
      "        description: Media type e.g. json or txt\n",
      "        schema:\n",
      "          type: string\n",
      "          example: json or txt \n",
      "        required: true\n",
      "      responses:\n",
      "        '200':\n",
      "          description: Success\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                type: object\n",
      "                properties:\n",
      "                  Gene:\n",
      "                    type: string\n",
      "                    description: Entrez Gene ID\n",
      "                  KEGG_COMPOUND_ID:\n",
      "                    type: string\n",
      "                    description: KEGG Compound IDs\n",
      "                  REFMET_NAME:\n",
      "                    type: string\n",
      "                    description: Metabolomics Workbench RefMet name\n",
      "                  KEGG_REACTION_ID:\n",
      "                    type: string\n",
      "                    description: KEGG Reaction IDs\n",
      "                  METSTAT_LINK:\n",
      "                    type: string\n",
      "                    description: Link to metabolite statistics in Metabolomics Workbench\n",
      "            text/plain:\n",
      "              schema:\n",
      "                type: string\n",
      "                example: pong\n",
      "          x-responseValueType:\n",
      "          - x-path: gene_id\n",
      "            x-valueType: https://identifiers.org/ncbigene\n",
      "          - x-path: KEGG_COMPOUND_ID\n",
      "            x-valueType: https://www.genome.jp/kegg/compound/\n",
      "          - x-path: REFMET_NAME\n",
      "            x-valueType: https://www.metabolomicsworkbench.org/databases/refmet/index.php\n",
      "          - x-path: KEGG_REACTION_ID\n",
      "            x-valueType: https://www.genome.jp/kegg/reaction/\n",
      "  /studies/species/{species_id}/GeneIDType/{geneID_type}/GeneInfoStr/{gene_ID}/anatomy/{anatomy_name}/disease/{disease_name}/phenotype/{phenotype_name}/viewType/{vtf}:\n",
      "    get:\n",
      "      description: Fetch all the studies in the Metabolomics Workbench for a given species, gene or list of genes, anatomy or tissue type, disease and phenotype.\n",
      "      parameters:\n",
      "      - in: path\n",
      "        name: species_id\n",
      "        description: The unique species name or identifier  like hsa, Human, mmu, Mouse.\n",
      "        schema:\n",
      "          type: string\n",
      "        example: hsa\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: geneID_type\n",
      "        description: The unique Gene ID type like ENTREZID, SYMBOL, SYMBOL_OR_ALIAS, UNIPROT, ENSEMBL or REFSEQ\n",
      "        schema:\n",
      "          type: string\n",
      "        example: SYMBOL\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: gene_ID\n",
      "        description: The unigue gene identifier (e.g. 3098) in any one of the known formats (e.g. ENTREZID ) or double tab separated list of identifiers (3098__6120) \n",
      "        schema:\n",
      "          type: string\n",
      "          example: HK1\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: anatomy_name\n",
      "        description: The anatomy or tissue name (e.g. Blood, Lung, Liver)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: Blood or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: disease_name\n",
      "        description: The disease name (e.g. Diabetes, Fatty liver disease)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: Diabetes or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: phenotype_name\n",
      "        description: The phenotype name (e.g. BMI)\n",
      "        schema:\n",
      "          type: string\n",
      "          example: BMI or NA (for unspecified)\n",
      "        required: true\n",
      "      - in: path\n",
      "        name: vtf\n",
      "        description: Media type e.g. json or txt\n",
      "        schema:\n",
      "          type: string\n",
      "          example: json or txt \n",
      "        required: true\n",
      "      responses:\n",
      "        '200':\n",
      "          description: Success\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                type: object\n",
      "                properties:\n",
      "                  KEGG_COMPOUND_ID:\n",
      "                    type: string\n",
      "                    description: KEGG Compound IDs\n",
      "                  REFMET_NAME:\n",
      "                    type: string\n",
      "                    description: Metabolomics Workbench unique Refmet name\n",
      "                  STUDY_ID:\n",
      "                    type: string\n",
      "                    description: A unique identifier for the study\n",
      "            text/plain:\n",
      "              schema:\n",
      "                type: string\n",
      "                example: pong\n",
      "          x-responseValueType:\n",
      "          - x-path: KEGG_COMPOUND_ID\n",
      "            x-valueType: https://www.genome.jp/kegg/compound/\n",
      "          - x-path: REFMET_NAME\n",
      "            x-valueType: https://www.metabolomicsworkbench.org/databases/refmet/index.php\n",
      "\n",
      "openapi: 3.0.0\n",
      "info:\n",
      "  title: REST API for MetNet\n",
      "  version: \"1.0.0\"\n",
      "  description: \"Given a list of metabolites, e.g., metabolites with significant change between two conditions such as disease/normal or treatment/control in a metabolomics study obtained by using MetENP (https://github.com/metabolomicsworkbench/MetENP) or another tool, a researcher may want to find what are the pathways and functions affected. MetENP provides a list of metabolic pathways affected, but it does not provide such information for signaling/regulatory pathways affected, e.g., using protein-protein interaction (PPI) information. MetNet, which is a metabolite-centric tool, fills that gap. The user is strongly encouraged to understand MetENP before using MetNet. MetNet uses several features from MetENP such as metabolite name harmonization using REFMET, metabolite class enrichment, metabolic pathway enrichment and visualization and identification of reactions related to the given metabolites and the genes (enzymes) catalyzing these reactions. The list of genes is used to develop their PPI network using STRING-DB APIs. Currently, MetNet is available as a REST API. The MetNet REST API provides HTTPS-based access to MetNet via a web-browser or scripts in several programming languages such as PHP, R, Python, that can handle HTTPS requests. The results are provided as a json object or a table with the columns FileDescription and FileURL. The components of the results can be accessed following these URLs. Please note that in the REST interface, the order of the parameters is fixed. While the MetNet REST API can be used in stand-alone mode, it is best used through a workflow development tool such as the NIH Common Fund Data Ecosystem (CFDE) Workflow Builder Tool (WBT) available at https://playbook-workflow-builder.cloud (see also https://github.com/nih-cfde/playbook-partnership/ and please note that some features of this API may be available only in a separate development instance available at https://github.com/metabolomicsworkbench/playbook-partnership/tree/playbook-partnership-mano-20221129). Downstream of the metabolite-related gene list, using the WBT, one can develop gene regulatory networks and then perform functional interpretation through pathway/gene set enrichment. The WBT enables use of our MetGENE tool (https://github.com/metabolomicsworkbench/MetGENE (web site), https://smart-api.info/ui/342e4cec92030d74efd84b61650fb0ea (SmartAPI)), where, starting with one or more genes, the related reactions and metabolites can be identified and serve as a starting list of metabolites for MetNet.\"\n",
      "  license:\n",
      "    name: Free non-commercial use\n",
      "    url: https://github.com/metabolomicsworkbench/MetNet/blob/main/LICENSE\n",
      "  contact:\n",
      "    email: mano@sdsc.edu\n",
      "servers:\n",
      "  - description: MetNet (Metabolite enrichment, pathways and networks)\n",
      "    url: https://bdcw.org/MetENP/rest\n",
      "paths:\n",
      "  #List of metabolites directly specified\n",
      "  #https://bdcw.org/MetENP/rest/metclass/sub_class/updown_fillcolor/red__green__blue/enrich_stats/HG/no/1/sps/hsa/padj/fdr/kegg_comp_path/FALSE/geneoption/TRUE/PPIopt/1_1000_400/location/0/metlistfname/NAD%25252B%25255CnNADH%25255CnNADPH%25255CnNADP%25252B%25255CnGlucose%2525206-phosphate%25255Cn6-Phosphonoglucono-D-lactone%25255CnRibulose%2525205-phosphate%25255Cn6-Phosphogluconic%252520acid%25255CnXylulose%2525205-phosphate%25255CnGlyceraldehyde%2525203-phosphate%25255CnErythrose%2525204-phosphate%25255CnSedoheptulose%2525207-phosphate%25255CnFructose%2525206-phosphate%25255CnRibose%2525205-phosphate%25255CnATP%25255CnADP%25255CnXylulose/View/json\n",
      "  #and list of metabolites specified in a web-accessible file\n",
      "  #https://bdcw.org/MetENP/rest/metclass/sub_class/updown_fillcolor/red__green__blue/enrich_stats/HG/no/1/sps/hsa/padj/fdr/kegg_comp_path/FALSE/geneoption/TRUE/PPIopt/1_1000_400/location/1/metlistfname/https%25253A%25252F%25252Fsc-cfdewebdev.sdsc.edu%25252Ftmp%25252Fmetlist.txt/View/json\n",
      "  /metclass/{metclass}/updown_fillcolor/{updown_fillcolor}/enrich_stats/{enrich_stats}/no/{min_num}/sps/{species_id}/padj/{padj}/kegg_comp_path/{kegg_comp_path}/geneoption/{geneoption}/PPIopt/{PPIopt}/location/{location}/metlistfname/{metlistfname}/View/{json_or_txt}:\n",
      "    get:\n",
      "      description: Perform MetENP analysis for a list of metabolites specified in a file or directly as a parameter, followed by development of a PPI network of the genes associated with the metabolites. The file URL or direct list of metabolites (separated by \\n) is encoded thrice. This is because the server performs automatic decoding twice. Hence, to retain  encoded (once) URL or list, triple encoding is required in the current version.\n",
      "      parameters:\n",
      "      #Types of parameters: https://swagger.io/docs/specification/describing-parameters\n",
      "      - in: path\n",
      "        name: metclass\n",
      "        description: Level of metabolite class enrichment \n",
      "        schema:\n",
      "          type: string\n",
      "        example: sub_class, main_class, super_class\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: updown_fillcolor\n",
      "        description: Color scheme used in metabolite class count \n",
      "        schema:\n",
      "          type: string\n",
      "        example: red__green__blue [red for count of metabolites increased, green for count of metabolites decreased and blue for not differentiating or when fold-change is not available]\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: enrich_stats\n",
      "        description: Method used for enrichment such as hypergeometric distribution\n",
      "        schema:\n",
      "          type: string\n",
      "        example: HG for hypergeometric distribution\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: min_num\n",
      "        description: Minimum number of metabolites in a pathway/class needed to include in the results \n",
      "        schema:\n",
      "          type: integer\n",
      "        example: 1, 2, or 3 [decrease this number if results do not include an expected pathway/class]\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: species_id\n",
      "        description: The unique species name as its three letter code \n",
      "        schema:\n",
      "          type: string\n",
      "        example: hsa [for Human], mmu [for Mouse], rno [for Rat]\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: padj\n",
      "        description: Method to compute adjust p-value for metabolite/class enrichment \n",
      "        schema:\n",
      "          type: string\n",
      "        example: fdr, BH, holm, hochberg, hommel, bonferroni, BY [see R function p.adjust]\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: kegg_comp_path\n",
      "        description: If enrichment using full list of KEGG pathways should be performed \n",
      "        schema:\n",
      "          type: string\n",
      "        example: TRUE or FALSE\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: geneoption\n",
      "        description: If the reactions and genes/enzymes related to the metabolites should be identified\n",
      "        schema:\n",
      "          type: string\n",
      "        example: TRUE or FALSE\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: PPIopt\n",
      "        description: Options for identifying PPI using STRING-DB in the format 1_1000_400 where the first number means yes (1, i.e., indeed identify PPI) or no (0; then other parameters are meaningless), the second number 1000 denotes the maximum number of edges per gene/protein (https://string-db.org/cgi/help.pl?subpage=api%23getting-all-the-string-interaction-partners-of-the-protein-set ; reduce this number if API returns without completing) and the third number 400 denotes the score cutoff (between 0 and 1000; 400 is moderate, 700 is high, 900 is very high).\n",
      "        schema:\n",
      "          type: string\n",
      "          example: 1_1000_400, 1_1500_700\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: location\n",
      "        description: If the next parameter is a URL to a file location/path (1) or no (0)\n",
      "        schema:\n",
      "          type: integer\n",
      "          example: 1 or 0\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: metlistfname\n",
      "        description: Triple encoded (1) URL to the file with list of metabolites (one metabolite per line) or (2) the full string of list of metabolites separated by \\n. This requirement makes it difficult to directly use this API. However, to get an example, one can leave the value of this argument unspecified so that the API can provide an example in the message. In triple encoding, / becomes %25252F. If it appears as %2525252F, then it has been encoded one extra time by the OpenAPI interpreter. In that case, please replace the leading %25 with % at all places once.\n",
      "        schema:\n",
      "          type: string\n",
      "          example: https%253A%252F%252Fsc-cfdewebdev.sdsc.edu%252Ftmp%252Fmetlist.txt (file URL) or NAD%252B%255CnNADH%255CnNADPH%255CnNADP%252B%255CnGlucose%25206-phosphate%255Cn6-Phosphonoglucono-D-lactone%255CnRibulose%25205-phosphate%255Cn6-Phosphogluconic%2520acid%255CnXylulose%25205-phosphate%255CnGlyceraldehyde%25203-phosphate%255CnErythrose%25204-phosphate%255CnSedoheptulose%25207-phosphate%255CnFructose%25206-phosphate%255CnRibose%25205-phosphate%255CnATP%255CnADP%255CnXylulose (list of metabolites directly specified)\n",
      "        required: true\n",
      "        #\n",
      "      - in: path\n",
      "        name: json_or_txt\n",
      "        description: The output (View) format, json or txt\n",
      "        schema:\n",
      "          type: string\n",
      "          example: json, txt\n",
      "        required: true\n",
      "      responses:\n",
      "        #https://swagger.io/docs/specification/describing-responses/\n",
      "        '200':\n",
      "          description: Result of applying MetENP on a list of metabolites [list of URLs of the component files as a json object]\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                type: object\n",
      "                properties:\n",
      "                  FileDescription:\n",
      "                    type: string\n",
      "                    description: Description of the file containing a specific result, e.g., count plot, enrichment or gene list\n",
      "                  FileURL:\n",
      "                    type: string\n",
      "                    description: URL for the file described\n",
      "          x-responseValueType:\n",
      "          - x-path: FileDescription\n",
      "            x-valueType: string\n",
      "          - x-path: FileURL\n",
      "            x-valueType: url\n",
      "        '406':\n",
      "          description: URL/path format not acceptable\n",
      "          content:\n",
      "            application/json:\n",
      "              schema:\n",
      "                $ref: '#/components/schemas/Error'\n",
      "components:\n",
      "  responses:\n",
      "    NotFound:\n",
      "      description: The specified resource was not found\n",
      "      content:\n",
      "        application/json:\n",
      "          schema:\n",
      "            $ref: '#/components/schemas/Error'\n",
      "    Unauthorized:\n",
      "      description: Unauthorized\n",
      "      content:\n",
      "        application/json:\n",
      "          schema:\n",
      "            $ref: '#/components/schemas/Error'\n",
      "  schemas:\n",
      "    # Schema for error response body\n",
      "    Error:\n",
      "      type: object\n",
      "      properties:\n",
      "        code:\n",
      "          type: string\n",
      "        message:\n",
      "          type: string\n",
      "      required:\n",
      "        - code\n",
      "        - message\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for error_id in error_list:\n",
    "    doc=SmartAPI.get(error_id)\n",
    "    print(doc.raw.decode('utf-8'))\n",
    "    print(type(doc.raw.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=\"/Users/nacosta/Documents/smartAPI/WORKING_BRANCH/add-validation/smartAPI/src/smartapi_schemav2_report_20240729165259.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'responsible developers' is not one of ['responsible organization', 'responsible developer', 'contributor', 'support']\n",
      "IDs: 03283cc2b21c077be6794e1704b1d230, e3edd325c76f2992a111b43a907a4870, b99c6dd64abcefe87dcd0a51c249ee6d, 00fb85fc776279163199e6c50f6ddfc6, edeb26858bd27d0322af93e7a9e08761, a7f784626a426d054885a5f33f17d3f8, 1d288b3a3caf75d541ffaae3aab386c8, 34bad236d77bea0a0ee6c6cba5be54a6, 77ed27f111262d0289ed4f4071faa619, b772ebfbfa536bba37764d7fddb11d6f, e481efd21f8e8c1deac05662439c2294, e9eb40ff7ad712e4e6f4f04b964b5966, 55a223c6c6e0291dbd05f2faf27d16f4, b48c34df08d16311e3bca06b135b828d, f1b8f64c316a01d1722f0fb842499fe5, 32f36164fabed5d3abe6c2fd899c9418, 895ec14a3650ec7ad85959a2d1554e2f, 1138c3297e8e403b6ac10cff5609b319, 1f47552dabd67351d4c625adb0a10d00, f339b28426e7bf72028f60feefcd7465, 38e9e5169a72aee3659c9ddba956790d, 68f12100e74342ae0dd5013d5f453194, cc857d5b7c8b7609b5bbb38ff990bfff, 316eab811fd9ef1097df98bcaa9f7361, ec6d76016ef40f284359d17fbf78df20, 02af7d098ab304e80d6f4806c3527027, a5b0ec6bfde5008984d4b6cde402d61f, 5a4c41bf2076b469a0e9cfcf2f2b8f29\n",
      "Details: \n",
      "Failed validating 'enum' in schema['properties']['info']['properties']['contact']['properties']['x-role']:\n",
      "    {'enum': ['responsible organization',\n",
      "              'responsible developer',\n",
      "              'contributor',\n",
      "              'support'],\n",
      "\n",
      "\n",
      "Error: 'x-path' is a required property\n",
      "IDs: 67932b75e2c51d1e1da2bf8263e59f0a, 7b183d07d82d93af7a0ebff996bb75bf, c806f9a29e61e08a333260ee27a7d7e4, 7439c6cae79dc74f0631863408088e81, da745f0b6c95ce27e9769a4a0d8d0a15, 3c5e198cfb362c654ed695727b7e02f0, a9baab984f6af0021aaece6a163e0cf4, ee94b34f03e2506717ba2f6325a2d0b2, ef26413a3480e6facafae94ba44da3d8, 1ad2cba40cb25cd70d00aa8fba9cfaf3, d7d1cc9bbe04ad9936076ca5aea904fe, 66ee5e997a2d40d8cbede03add772651\n",
      "Details: \n",
      "Failed validating 'required' in schema['properties']['paths']['patternProperties']['^\\\\/']['patternProperties']['get|put|post|delete|options|head|patch|trace']['properties']['responses']['patternProperties']['[1-5](?:\\\\d{2}|XX)']['properties']['x-responseValueType']['items']:\n",
      "    {'properties': {'x-path': {'description': 'The path, using dot '\n",
      "                                              'notation, to the element of '\n",
      "                                              'interest',\n",
      "                               'type': 'string'},\n",
      "\n",
      "\n",
      "Error: 'document creator' is not one of ['responsible organization', 'responsible developer', 'contributor', 'support']\n",
      "IDs: aaff750928be8fb09485e953a78e93a2\n",
      "Details: \n",
      "Failed validating 'enum' in schema['properties']['info']['properties']['x-otherContacts']['items']['properties']['x-role']:\n",
      "    {'enum': ['responsible organization',\n",
      "              'responsible developer',\n",
      "              'contributor',\n",
      "              'support'],\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Open the file\n",
    "with open(report, 'r') as file:\n",
    "    # Initialize a flag for the \"Detailed Error Reports\" section\n",
    "    detailed_errors = False\n",
    "    # Initialize a dictionary to store the error messages and IDs\n",
    "    error_dict = {}\n",
    "    # Initialize a dictionary to store the detailed error information\n",
    "    error_info_dict = {}\n",
    "\n",
    "    # Loop through each line in the file\n",
    "    for line in file:\n",
    "        # If the line contains \"Detailed Error Reports\", set the flag to True\n",
    "        if \"Detailed Error Reports\" in line:\n",
    "            detailed_errors = True\n",
    "\n",
    "        # If the flag is True, process the line\n",
    "        if detailed_errors:\n",
    "            # If the line contains \"Schema Validation Error for ID\", extract the ID and error message\n",
    "            if \"Schema Validation Error for ID\" in line:\n",
    "                id = re.search(r\"for ID (.*):\", line).group(1)\n",
    "                error = re.search(r\": (.*)\", line).group(1)\n",
    "                # If the error message is already in the dictionary, append the ID to the list of IDs\n",
    "                if error in error_dict:\n",
    "                    error_dict[error].append(id)\n",
    "                # If the error message is not in the dictionary, add it with the ID as the first item in the list of IDs\n",
    "                else:\n",
    "                    error_dict[error] = [id]\n",
    "                    # Store the next 6 lines as the detailed error information\n",
    "                    error_info_dict[error] = ''.join([next(file) for _ in range(6)])\n",
    "\n",
    "# Print out the error messages, IDs, and detailed error information\n",
    "for error, ids in error_dict.items():\n",
    "    print(f\"Error: {error}\")\n",
    "    print(f\"IDs: {', '.join(ids)}\")\n",
    "    print(f\"Details: {error_info_dict[error]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the translator repos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "base_dir = \"/Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry\"\n",
    "pattern = re.compile(r'BioThings (\\w+)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the error API ids for the `responsible developers` typo error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 ids\n",
      "BioThings Rhea API\n",
      "BioThings DGIdb API\n",
      "BioThings BioPlanet Pathway-Gene API\n",
      "BioThings DDInter API\n",
      "BioThings PFOCR API\n",
      "BioThings DISEASES API\n",
      "BioThings SEMMEDDB API\n",
      "BioThings GO Molecular Function API\n",
      "BioThings MGIgene2phenotype API\n",
      "BioThings RARe-SOURCE API\n",
      "Biothings Therapeutic Target Database API\n",
      "BioThings InnateDB API\n",
      "BioThings BioPlanet Pathway-Disease API\n",
      "BioThings SuppKG API\n",
      "BioThings FooDB API\n",
      "BioThings IDISK API\n",
      "BioThings FoodData Central API\n",
      "BioThings repoDB API\n",
      "BioThings EBIgene2phenotype API\n",
      "BioThings GO Cellular Component API\n",
      "BioThings BindingDB API\n",
      "BioThings AGR API\n",
      "BioThings GO Biological Process API\n",
      "BioThings GTRx API\n",
      "BioThings UBERON API\n",
      "Multiomics Wellness KP API\n",
      "BioThings HPO API\n",
      "Translator Annotation Service\n"
     ]
    }
   ],
   "source": [
    "error_ids_res_devs = ['03283cc2b21c077be6794e1704b1d230', 'e3edd325c76f2992a111b43a907a4870', 'b99c6dd64abcefe87dcd0a51c249ee6d', '00fb85fc776279163199e6c50f6ddfc6', 'edeb26858bd27d0322af93e7a9e08761', 'a7f784626a426d054885a5f33f17d3f8', '1d288b3a3caf75d541ffaae3aab386c8', '34bad236d77bea0a0ee6c6cba5be54a6', '77ed27f111262d0289ed4f4071faa619', 'b772ebfbfa536bba37764d7fddb11d6f', 'e481efd21f8e8c1deac05662439c2294', 'e9eb40ff7ad712e4e6f4f04b964b5966', '55a223c6c6e0291dbd05f2faf27d16f4', 'b48c34df08d16311e3bca06b135b828d', 'f1b8f64c316a01d1722f0fb842499fe5', '32f36164fabed5d3abe6c2fd899c9418', '895ec14a3650ec7ad85959a2d1554e2f', '1138c3297e8e403b6ac10cff5609b319', '1f47552dabd67351d4c625adb0a10d00', 'f339b28426e7bf72028f60feefcd7465', '38e9e5169a72aee3659c9ddba956790d', '68f12100e74342ae0dd5013d5f453194', 'cc857d5b7c8b7609b5bbb38ff990bfff', '316eab811fd9ef1097df98bcaa9f7361', 'ec6d76016ef40f284359d17fbf78df20', '02af7d098ab304e80d6f4806c3527027', 'a5b0ec6bfde5008984d4b6cde402d61f', '5a4c41bf2076b469a0e9cfcf2f2b8f29']\n",
    "api_dict={}\n",
    "print(f\"{len(error_ids_res_devs)} ids\")\n",
    "\n",
    "for id_ in error_ids_res_devs:\n",
    "    doc=SmartAPI.get(id_)\n",
    "    # print(doc.__dict__.keys())\n",
    "    # print(doc.__dict__['_raw'])\n",
    "    raw_output = doc.raw.decode('utf-8')\n",
    "    yaml_doc = yaml.safe_load(raw_output)\n",
    "    print(yaml_doc['info']['title'])\n",
    "    api_dict[id_]=yaml_doc['info']['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(api_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the output of key: `['info']['contact']['x-role']` is the typo value - `responsible developers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'gglusman@isbscience.org', 'name': 'Gwenlyn Glusman', 'x-role': 'responsible developers', 'x-id': 'https://github.com/biothings'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n",
      "{'email': 'help@biothings.io', 'name': 'BioThings Team', 'x-id': 'https://github.com/biothings', 'x-role': 'responsible developers'}\n"
     ]
    }
   ],
   "source": [
    "for id_ in error_ids_res_devs:\n",
    "    doc=SmartAPI.get(id_)\n",
    "    # print(doc.__dict__.keys())\n",
    "    # print(doc.__dict__['_raw'])\n",
    "    raw_output = doc.raw.decode('utf-8')\n",
    "    yaml_doc = yaml.safe_load(raw_output)\n",
    "    print(yaml_doc['info']['contact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioThings Rhea API: rhea\n",
      "BioThings DGIdb API: dgidb\n",
      "BioThings BioPlanet Pathway-Gene API: bioplanet\n",
      "BioThings DDInter API: ddinter\n",
      "BioThings PFOCR API: pfocr\n",
      "BioThings DISEASES API: diseases\n",
      "BioThings SEMMEDDB API: semmeddb\n",
      "BioThings MGIgene2phenotype API: mgigene2phenotype\n",
      "****NOT FOUND:Biothings Therapeutic Target Database API****\n",
      "BioThings InnateDB API: innatedb\n",
      "BioThings BioPlanet Pathway-Disease API: bioplanet\n",
      "BioThings SuppKG API: suppkg\n",
      "BioThings IDISK API: idisk\n",
      "BioThings repoDB API: repodb\n",
      "BioThings EBIgene2phenotype API: ebigene2phenotype\n",
      "BioThings BindingDB API: bindingdb\n",
      "BioThings AGR API: agr\n",
      "BioThings GTRx API: gtrx\n",
      "BioThings UBERON API: uberon\n",
      "****NOT FOUND:Multiomics Wellness KP API****\n",
      "BioThings HPO API: hpo\n",
      "****NOT FOUND:Translator Annotation Service****\n"
     ]
    }
   ],
   "source": [
    "manual_edits=[]\n",
    "for value in api_dict.values():\n",
    "    match = pattern.search(value)\n",
    "    if match:\n",
    "        repo_name = match.group(1).lower()\n",
    "        repo_path = os.path.join(base_dir, repo_name)\n",
    "        if os.path.exists(repo_path):\n",
    "            print(f\"{value}: {repo_name}\")\n",
    "    else:\n",
    "        manual_edits.append(value)\n",
    "        print(f\"****NOT FOUND:{value}****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Biothings Therapeutic Target Database API',\n",
       " 'Multiomics Wellness KP API',\n",
       " 'Translator Annotation Service']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioThings Rhea API: rhea\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/rhea/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/rhea/smartapi.yaml: responsible developer\n",
      "BioThings DGIdb API: dgidb\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/openapi.yml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/openapi.yml: responsible developer\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/smartapi.yml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/smartapi.yml: responsible developer\n",
      "BioThings BioPlanet Pathway-Gene API: bioplanet\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-gene.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-gene.yaml: responsible developer\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-disease.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-disease.yaml: responsible developer\n",
      "BioThings DDInter API: ddinter\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ddinter/ddinter.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ddinter/ddinter.yaml: responsible developer\n",
      "BioThings PFOCR API: pfocr\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/pfocr/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/pfocr/smartapi.yaml: responsible developer\n",
      "BioThings DISEASES API: diseases\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/diseases/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/diseases/smartapi.yaml: responsible developer\n",
      "BioThings SEMMEDDB API: semmeddb\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/smartapi.yaml: responsible developer\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/version_without_operations.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/version_without_operations.yaml: responsible developer\n",
      "BioThings MGIgene2phenotype API: mgigene2phenotype\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/mgigene2phenotype/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/mgigene2phenotype/smartapi.yaml: responsible developer\n",
      "BioThings InnateDB API: innatedb\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/innatedb/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/innatedb/smartapi.yaml: responsible developer\n",
      "BioThings BioPlanet Pathway-Disease API: bioplanet\n",
      "BioThings SuppKG API: suppkg\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/suppkg/suppkg.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/suppkg/suppkg.yaml: responsible developer\n",
      "BioThings IDISK API: idisk\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/idisk/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/idisk/smartapi.yaml: responsible developer\n",
      "BioThings repoDB API: repodb\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/repodb/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/repodb/smartapi.yaml: responsible developer\n",
      "BioThings EBIgene2phenotype API: ebigene2phenotype\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ebigene2phenotype/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ebigene2phenotype/smartapi.yaml: responsible developer\n",
      "BioThings BindingDB API: bindingdb\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bindingdb/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bindingdb/smartapi.yaml: responsible developer\n",
      "BioThings AGR API: agr\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/agr/agr.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/agr/agr.yaml: responsible developer\n",
      "BioThings GTRx API: gtrx\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/gtrx/gtrx.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/gtrx/gtrx.yaml: responsible developer\n",
      "BioThings UBERON API: uberon\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/uberon/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/uberon/smartapi.yaml: responsible developer\n",
      "BioThings HPO API: hpo\n",
      "Before change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/hpo/smartapi.yaml: responsible developers\n",
      "After change 'x-role' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/hpo/smartapi.yaml: responsible developer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('error_log.txt', 'w') as error_file:\n",
    "    for value in api_dict.values():\n",
    "        match = pattern.search(value)\n",
    "        if match:\n",
    "            repo_name = match.group(1).lower()\n",
    "            repo_path = os.path.join(base_dir, repo_name)\n",
    "            if os.path.exists(repo_path):\n",
    "                print(f\"{value}: {repo_name}\")\n",
    "                for file in glob.glob(os.path.join(repo_path, \"*.yml\")) + glob.glob(os.path.join(repo_path, \"*.yaml\")):\n",
    "                    try:\n",
    "                        with open(file, 'r') as yaml_file:\n",
    "                            yaml_doc = yaml.safe_load(yaml_file)\n",
    "                            if 'x-role' in yaml_doc['info']['contact'] and yaml_doc['info']['contact']['x-role'] == 'responsible developers':\n",
    "                                print(f\"Before change 'x-role' in {file}: {yaml_doc['info']['contact']['x-role']}\")\n",
    "                                yaml_doc['info']['contact']['x-role'] = 'responsible developer'\n",
    "                                print(f\"After change 'x-role' in {file}: {yaml_doc['info']['contact']['x-role']}\")\n",
    "                        with open(file, 'w') as yaml_file:\n",
    "                            yaml.safe_dump(yaml_doc, yaml_file)\n",
    "                    except KeyError:\n",
    "                        error_file.write(f\"Error in {repo_name}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioThings Rhea API: rhea\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/rhea/smartapi.yaml\n",
      "BioThings DGIdb API: dgidb\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/openapi.yml\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/dgidb/smartapi.yml\n",
      "BioThings BioPlanet Pathway-Gene API: bioplanet\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-gene.yaml\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-disease.yaml\n",
      "BioThings DDInter API: ddinter\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ddinter/ddinter.yaml\n",
      "BioThings PFOCR API: pfocr\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/pfocr/smartapi.yaml\n",
      "BioThings DISEASES API: diseases\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/diseases/smartapi.yaml\n",
      "BioThings SEMMEDDB API: semmeddb\n",
      "Replaced 'responsible developers' with 'responsible developer' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/generated_operations.yaml\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/smartapi.yaml\n",
      "Replaced 'responsible developers' with 'responsible developer' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/generated_list.yaml\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/semmeddb/version_without_operations.yaml\n",
      "BioThings MGIgene2phenotype API: mgigene2phenotype\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/mgigene2phenotype/smartapi.yaml\n",
      "BioThings InnateDB API: innatedb\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/innatedb/smartapi.yaml\n",
      "BioThings BioPlanet Pathway-Disease API: bioplanet\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-gene.yaml\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bioplanet/bioplanet-pathway-disease.yaml\n",
      "BioThings SuppKG API: suppkg\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/suppkg/suppkg.yaml\n",
      "BioThings IDISK API: idisk\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/idisk/smartapi.yaml\n",
      "BioThings repoDB API: repodb\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/repodb/smartapi.yaml\n",
      "BioThings EBIgene2phenotype API: ebigene2phenotype\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/ebigene2phenotype/smartapi.yaml\n",
      "BioThings BindingDB API: bindingdb\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/bindingdb/smartapi.yaml\n",
      "BioThings AGR API: agr\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/agr/agr.yaml\n",
      "BioThings GTRx API: gtrx\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/gtrx/gtrx.yaml\n",
      "BioThings UBERON API: uberon\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/uberon/smartapi.yaml\n",
      "BioThings HPO API: hpo\n",
      "Replaced 'responsible developers' with 'responsible organization' in /Users/nacosta/Documents/smartAPI/WORKING_BRANCH/transl-api-reg/translator-api-registry/hpo/smartapi.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "def replace_in_file(file_path, old_string, new_string):\n",
    "    # Create temporary file read/write\n",
    "    with tempfile.NamedTemporaryFile(mode='r+', delete=False) as temp_file:\n",
    "        with open(file_path, 'r') as yaml_file:\n",
    "            for line in yaml_file:\n",
    "                # replace old_string with new_string\n",
    "                temp_file.write(line.replace(old_string, new_string))\n",
    "        # Copy the temp file to the original location\n",
    "        os.replace(temp_file.name, file_path)\n",
    "\n",
    "file_ct=0\n",
    "# Use the function in your code\n",
    "with open('error_log.txt', 'w') as error_file:\n",
    "    for value in api_dict.values():\n",
    "        match = pattern.search(value)\n",
    "        if match:\n",
    "            repo_name = match.group(1).lower()\n",
    "            repo_path = os.path.join(base_dir, repo_name)\n",
    "            if os.path.exists(repo_path):\n",
    "                print(f\"{value}: {repo_name}\")\n",
    "                for file in glob.glob(os.path.join(repo_path, \"*.yml\")) + glob.glob(os.path.join(repo_path, \"*.yaml\")):\n",
    "                    try:\n",
    "                        # Load the YAML file into a Python dictionary\n",
    "                        with open(file, 'r') as yaml_file:\n",
    "                            data = yaml.safe_load(yaml_file)\n",
    "\n",
    "                        contact_name = data.get('info', {}).get('contact', {}).get('name')\n",
    "                        # # Check if info.contact.name equals \"Biothings Team\"\n",
    "                        if contact_name and \"BioThings Team\" in contact_name:\n",
    "                            replace_in_file(file, 'responsible developers', 'responsible organization')\n",
    "                            print(f\"Replaced 'responsible developers' with 'responsible organization' in {file}\")\n",
    "                        else:\n",
    "                            replace_in_file(file, 'responsible developers', 'responsible developer')\n",
    "                            print(f\"Replaced 'responsible developers' with 'responsible developer' in {file}\")\n",
    "                        file_ct += 1\n",
    "                    except KeyError:\n",
    "                        error_file.write(f\"Error in {repo_name}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "def replace_in_file(file_path, old_string, new_string):\n",
    "    # Create temporary file read/write\n",
    "    with tempfile.NamedTemporaryFile(mode='r+', delete=False) as temp_file:\n",
    "        with open(file_path, 'r') as yaml_file:\n",
    "            for line in yaml_file:\n",
    "                # replace old_string with new_string\n",
    "                temp_file.write(line.replace(old_string, new_string))\n",
    "        # Copy the temp file to the original location\n",
    "        os.replace(temp_file.name, file_path)\n",
    "\n",
    "def search_and_replace(directory, old_string, new_string):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.yml') or file.endswith('.yaml'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                replace_in_file(file_path, old_string, new_string)\n",
    "\n",
    "# Use the function in your code\n",
    "search_and_replace(base_dir, 'responsible developers', 'responsible developer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('error_log.txt', 'w') as error_file:\n",
    "    for value in api_dict.values():\n",
    "        match = pattern.search(value)\n",
    "        if match:\n",
    "            repo_name = match.group(1).lower()\n",
    "            repo_path = os.path.join(base_dir, repo_name)\n",
    "            if os.path.exists(repo_path):\n",
    "                print(f\"{value}: {repo_name}\")\n",
    "                for file in glob.glob(os.path.join(repo_path, \"*.yml\")) + glob.glob(os.path.join(repo_path, \"*.yaml\")):\n",
    "                    try:\n",
    "                        with open(file, 'r') as yaml_file:\n",
    "                            yaml_doc = yaml.safe_load(yaml_file)\n",
    "                            if 'x-role' in yaml_doc['info']['contact'] and yaml_doc['info']['contact']['x-role'] == 'responsible developers':\n",
    "                                print(f\"Before change 'x-role' in {file}: {yaml_doc['info']['contact']['x-role']}\")\n",
    "                                yaml_doc['info']['contact']['x-role'] = 'responsible developer'\n",
    "                                print(f\"After change 'x-role' in {file}: {yaml_doc['info']['contact']['x-role']}\")\n",
    "                        with open(file, 'w') as yaml_file:\n",
    "                            yaml.safe_dump(yaml_doc, yaml_file)\n",
    "                    except KeyError:\n",
    "                        error_file.write(f\"Error in {repo_name}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
